[
  {
    "objectID": "posts/cudacheck.html",
    "href": "posts/cudacheck.html",
    "title": "gpu check",
    "section": "",
    "text": "import torch\ntorch.cuda.is_available()\n\nTrue\n\n\n\n!nvidia-smi\n\nMon Apr  3 22:00:02 2023       \n+-----------------------------------------------------------------------------+\n| NVIDIA-SMI 525.105.17   Driver Version: 525.105.17   CUDA Version: 12.0     |\n|-------------------------------+----------------------+----------------------+\n| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n|                               |                      |               MIG M. |\n|===============================+======================+======================|\n|   0  NVIDIA GeForce ...  Off  | 00000000:01:00.0  On |                  N/A |\n| 30%   28C    P8    26W / 250W |    349MiB / 11264MiB |      3%      Default |\n|                               |                      |                  N/A |\n+-------------------------------+----------------------+----------------------+\n                                                                               \n+-----------------------------------------------------------------------------+\n| Processes:                                                                  |\n|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n|        ID   ID                                                   Usage      |\n|=============================================================================|\n+-----------------------------------------------------------------------------+\n\n\n\n\n\nCopyrightCopyright tamuraup. 2024. All Rights Reserved"
  },
  {
    "objectID": "posts/post-with-code/index.html",
    "href": "posts/post-with-code/index.html",
    "title": "Quarto Basics",
    "section": "",
    "text": "For a demonstration of a line plot on a polar axis, see Figure 1.\n\n\nCode\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nr = np.arange(0, 2, 0.01)\ntheta = 2 * np.pi * r\nfig, ax = plt.subplots(\n  subplot_kw = {'projection': 'polar'} \n)\nax.plot(theta, r)\nax.set_rticks([0.5, 1, 1.5, 2])\nax.grid(True)\nplt.show()\n\n\n\n\n\n\n\n\nFigure 1: A line plot on a polar axis\n\n\n\n\n\n\n\n\nCopyrightCopyright tamuraup. 2024. All Rights Reserved"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "雑なメモ置き場",
    "section": "",
    "text": "numpy, pandas.DataFrame で多数決をとる\n\n\n\n\n\n\nml\n\n\n\n\n\n\n\n\n\n2024 年 05 月 12 日\n\n\n\n\n\n\n\n\n\n\n\n\nPyTorch 学習結果の再現性確保\n\n\n\n\n\n\nml\n\n\n\n\n\n\n\n\n\n2024 年 05 月 11 日\n\n\n\n\n\n\n\n\n\n\n\n\nBCEWithLogitsLoss の確認\n\n\n\n\n\n\nml\n\n\n\n\n\n\n\n\n\n2024 年 05 月 09 日\n\n\n\n\n\n\n\n\n\n\n\n\n画像グリッド描画サンプル\n\n\n\n\n\n\nnotebook\n\n\nimage\n\n\n\n\n\n\n\n\n\n2024 年 05 月 04 日\n\n\n\n\n\n\n\n\n\n\n\n\nAHC032 解説放送メモ\n\n\n\n\n\n\nahc\n\n\n\n\n\n\n\n\n\n2024 年 05 月 03 日\n\n\n\n\n\n\n\n\n\n\n\n\nchokudai search template\n\n\n\n\n\n\nahc\n\n\n\n\n\n\n\n\n\n2024 年 05 月 01 日\n\n\n\n\n\n\n\n\n\n\n\n\ngpu check\n\n\n\n\n\n\nnotebook\n\n\n\n\n\n\n\n\n\n2024 年 05 月 01 日\n\n\n\n\n\n\nNo matching items\n\nCopyrightCopyright tamuraup. 2024. All Rights Reserved"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "雑なメモを置いています。メモ書きなので間違っていることも書いているでしょう。\n\n\nCopyrightCopyright tamuraup. 2024. All Rights Reserved"
  },
  {
    "objectID": "posts/test.html",
    "href": "posts/test.html",
    "title": "Quarto Basics",
    "section": "",
    "text": "Red\nGreen\nBlue"
  },
  {
    "objectID": "posts/test.html#colors",
    "href": "posts/test.html#colors",
    "title": "Quarto Basics",
    "section": "",
    "text": "Red\nGreen\nBlue"
  },
  {
    "objectID": "posts/test.html#shapes",
    "href": "posts/test.html#shapes",
    "title": "Quarto Basics",
    "section": "2 Shapes",
    "text": "2 Shapes\n\nSquare\nCircle\nTriangle"
  },
  {
    "objectID": "posts/test.html#textures",
    "href": "posts/test.html#textures",
    "title": "Quarto Basics",
    "section": "3 Textures",
    "text": "3 Textures\n\nSmooth\nBumpy\nFuzzy"
  },
  {
    "objectID": "posts/2024-05-01-chokudaisearch.html",
    "href": "posts/2024-05-01-chokudaisearch.html",
    "title": "chokudai search template",
    "section": "",
    "text": "chokudai search の練習をしたのでメモ。\n#[derive(PartialEq, Eq, Clone)]\nstruct State {\n    score: i64,\n}\nimpl State {\n    fn new() -&gt; Self {\n        todo!()\n    }\n}\n\nimpl Ord for State {\n    fn cmp(&self, other: &Self) -&gt; Ordering {\n        self.score.cmp(&other.score)\n    }\n}\n\nimpl PartialOrd for State {\n    fn partial_cmp(&self, other: &Self) -&gt; Option&lt;Ordering&gt; {\n        Some(self.cmp(other))\n    }\n}\n\nfn simple_chokudai_search(inp: &Input, timer: &Timer) {\n    let mut beams: Vec&lt;LimitedMaximumHeap&lt;State&gt;&gt; = vec![LimitedMaximumHeap::new(500); 51];\n\n    let mut iter = 0;\n    let mut best = 0;\n    beams[0].push(State::new());\n\n    'outer: loop {\n        iter += 1;\n        if timer.t() &gt;= 1.0 {\n            break;\n        }\n\n        for depth in 0..beams.len() {\n            if depth % 10 == 0 && timer.t() &gt;= 1.0 {\n                break 'outer;\n            }\n            if beams[depth].is_empty() {\n                continue;\n            }\n            // ここで複数回 pop すると 幅 &gt; 1 ってこと？\n            let state = beams[depth].pop().unwrap();\n            // TODO: なにか処理\n        }\n    }\n}\n\n\n\nCopyrightCopyright tamuraup. 2024. All Rights Reserved"
  },
  {
    "objectID": "posts/2024-05-03_ahc032memo.html",
    "href": "posts/2024-05-03_ahc032memo.html",
    "title": "AHC032 解説放送メモ",
    "section": "",
    "text": "解説放送みたメモ"
  },
  {
    "objectID": "posts/2024-05-03_ahc032memo.html#解説放送メモ",
    "href": "posts/2024-05-03_ahc032memo.html#解説放送メモ",
    "title": "AHC032 解説放送メモ",
    "section": "解説放送メモ",
    "text": "解説放送メモ\n\n解説放送: https://www.youtube.com/watch?v=9JS0wXXNiZk\neijirou さん解法: https://atcoder.jp/contests/ahc032/submissions?f.User=eijirou\nwata さん解法: https://atcoder.jp/contests/ahc032/submissions/52151408"
  },
  {
    "objectID": "posts/2024-05-03_ahc032memo.html#考察",
    "href": "posts/2024-05-03_ahc032memo.html#考察",
    "title": "AHC032 解説放送メモ",
    "section": "考察",
    "text": "考察\n\n3*3 のマスをすべて MOD*0.8 以上にするためには 5^9 通り候補がほしい\n\n(ランダムに与えられたスタンプで 1 マスを MOD*4/5 以上にできる確率 1/5)\n\n近傍がなめらかでないので、焼きなましなどの局所探索は不適\n同じ 9 マスを操作するなら、左上の点は分散させたほうが場合の数が増える"
  },
  {
    "objectID": "posts/2024-05-03_ahc032memo.html#ビームサーチ",
    "href": "posts/2024-05-03_ahc032memo.html#ビームサーチ",
    "title": "AHC032 解説放送メモ",
    "section": "ビームサーチ",
    "text": "ビームサーチ\n\n評価関数: \\(確定スコア + K * MOD * (1 - 進行度) * 残りの操作回数\\) (\\(K\\) はハイパーパラメータ)\n\n進行度が小さい場合は、後でより上手く揃えられるように操作回数を残したい\n\n\n\nwata さんの言っている「操作回数別でビームを分ける」とは\nここでいうビームサーチは幅優先のビームサーチで「確定マス数」が深さに対応する。\n確定マス数を C とする。これを操作回数の基準として \\(\\pm W\\) 回の操作回数のズレを許容し、そのズレ幅ごとにビームをもつ。\n(例: コードの beam[W] はズレ幅 0 のビーム)\n\n\n揃えるマスの順\n35:30\n\n揃える順序は 3 マス揃えが連続しないほうが良い\nビームサーチの「確定スコア/確定マス数」を可視化することで確認している"
  },
  {
    "objectID": "posts/2024-05-03_ahc032memo.html#高速化",
    "href": "posts/2024-05-03_ahc032memo.html#高速化",
    "title": "AHC032 解説放送メモ",
    "section": "高速化",
    "text": "高速化\n\n不要なスタンプをできるだけ減らす工夫をしている\nスタンプを右上の値で分類し、右上マスを良い値にできるスタンプの候補を絞り込めるようにするなど\n\n\nK 分木の話\nwata さん実装の Searcher がそれ。\nやることは「3マス揃え」で話していることとほとんど同じ。\nMOD を K 個の区間に分けて、スタンプの 1 マス目の値で K 分割、2 マス目の値で K 分割 …\nのように分割する木の深さが i マス目の分割となる K 分木を作り、良いスタンプの探索を高速にできるようにする。"
  },
  {
    "objectID": "posts/2024-05-12_tasuketsu.html",
    "href": "posts/2024-05-12_tasuketsu.html",
    "title": "numpy, pandas.DataFrame で多数決をとる",
    "section": "",
    "text": "多数決を取ったメモ。 今回は行ごとの最頻値を求める。\nscipy.stats.mode を使うと楽。\nscipy.stats.mode — SciPy v1.13.0 Manual\nimport numpy as np\nimport scipy.stats as stats\na=np.array([[1,1,2],[3,4,5],[1,1,1]])\na\n\narray([[1, 1, 2],\n       [3, 4, 5],\n       [1, 1, 1]])\nb=np.array([[1,2,3],[3,4,1],[1,1,2]])\nb\n\narray([[1, 2, 3],\n       [3, 4, 1],\n       [1, 1, 2]])\nc=np.hstack((a,b))\nc\n\narray([[1, 1, 2, 1, 2, 3],\n       [3, 4, 5, 3, 4, 1],\n       [1, 1, 1, 1, 1, 2]])\nstats.mode(a,axis=1,keepdims=True)[0]\n\narray([[1],\n       [3],\n       [1]])\nstats.mode(b,axis=1,keepdims=True)[0]\n\narray([[1],\n       [1],\n       [1]])\nstats.mode(c,axis=1,keepdims=True)[0]\n\narray([[1],\n       [3],\n       [1]])"
  },
  {
    "objectID": "posts/2024-05-12_tasuketsu.html#pandas.dataframe",
    "href": "posts/2024-05-12_tasuketsu.html#pandas.dataframe",
    "title": "numpy, pandas.DataFrame で多数決をとる",
    "section": "pandas.DataFrame",
    "text": "pandas.DataFrame\nDataFrame にも mode 関数がある。\npandas.DataFrame.mode — pandas 2.2.2 ドキュメント\n\nimport pandas as pd\n\n\ndf=pd.DataFrame(a)\ndf\n\n\n\n\n\n\n\n\n\n0\n1\n2\n\n\n\n\n0\n1\n1\n2\n\n\n1\n3\n4\n5\n\n\n2\n1\n1\n1\n\n\n\n\n\n\n\n\n\ndf.mode(axis=1)\n\n\n\n\n\n\n\n\n\n0\n1\n2\n\n\n\n\n0\n1.0\nNaN\nNaN\n\n\n1\n3.0\n4.0\n5.0\n\n\n2\n1.0\nNaN\nNaN\n\n\n\n\n\n\n\n\n最頻値が複数あればその分の列が返るっぽい？ (ドキュメントに書いてなさそう)\n\ndf=pd.DataFrame(c)\ndf\n\n\n\n\n\n\n\n\n\n0\n1\n2\n3\n4\n5\n\n\n\n\n0\n1\n1\n2\n1\n2\n3\n\n\n1\n3\n4\n5\n3\n4\n1\n\n\n2\n1\n1\n1\n1\n1\n2\n\n\n\n\n\n\n\n\n\ndf.mode(axis=1)\n\n\n\n\n\n\n\n\n\n0\n1\n\n\n\n\n0\n1.0\nNaN\n\n\n1\n3.0\n4.0\n\n\n2\n1.0\nNaN"
  },
  {
    "objectID": "posts/2024-05-11-seed_everything.html",
    "href": "posts/2024-05-11-seed_everything.html",
    "title": "PyTorch 学習結果の再現性確保",
    "section": "",
    "text": "Pytorch Lightning で学習したとき、seed_everything で乱数固定すれば、同じ学習結果が得られると思っていたが実際にはそうでなかった。\n調べてみると、\nの設定も必要そうだった。Reproducibility — PyTorch 2.3 documentation\nこの 2 つを設定することで、内部で使用されるアルゴリズムを固定化できるとのこと。\n上記参考に以下の関数を呼ぶことで、同じ学習結果が得られるようになった。"
  },
  {
    "objectID": "posts/2024-05-11-seed_everything.html#その他参考",
    "href": "posts/2024-05-11-seed_everything.html#その他参考",
    "title": "PyTorch 学習結果の再現性確保",
    "section": "その他参考",
    "text": "その他参考\n\nhttps://qiita.com/north_redwing/items/1e153139125d37829d2d#cuda-convolution-benchmarking"
  },
  {
    "objectID": "posts/2024-05-09_bcewithlogitsloss_check.html",
    "href": "posts/2024-05-09_bcewithlogitsloss_check.html",
    "title": "BCEWithLogitsLoss の確認",
    "section": "",
    "text": "BCEWithLogitsLoss はマルチラベル分類のロスに使えることを知った\nBCEWithLogitsLoss\n\nimport numpy as np\nimport torch\n\n\ntarget = torch.ones([1, 10], dtype=torch.float32)  # 10 classes, batch size = 1\n# A prediction (logit)\noutput = torch.cat([torch.full([1, 5], 1.5),torch.full([1,5],1.0)],dim=1)\ncriterion = torch.nn.BCEWithLogitsLoss(reduction='none')\ncriterion(output, target)  # -log(sigmoid(output value))\n\ntensor([[0.2014, 0.2014, 0.2014, 0.2014, 0.2014, 0.3133, 0.3133, 0.3133, 0.3133,\n         0.3133]])\n\n\n\nsigmoid=torch.sigmoid(torch.Tensor([1.0,1.5]))\ntorch.log(sigmoid)\n\ntensor([-0.3133, -0.2014])\n\n\npos_weight は 各クラスで Positive/Negative のデータ数が不均衡な場合に設定すると良いらしい\n\n\n\nCopyrightCopyright tamuraup. 2024. All Rights Reserved"
  }
]